# EcoPulse 毕业设计 — 指导教授评审意见书### 一、 架构设计的“头重脚轻” (Architecture Asymmetry)



> **评审人身份**：大数据专业资深教授 / 毕业设计指导教师这是你项目目前最大的硬伤。

> **评审日期**：2026-02-12

> **评审依据**：全量代码审读 (CoreCode 1-6 + scripts) + README + 项目文档1.  **Serving 层的伪分布式**：

    *   **批评**：你后端用了 Spark 这种重型核武器去处理 2 亿条数据，结果到了 Serving 层（服务层），你居然把结果导成了 **CSV 文件** ([scripts/prepare_serving_data.py](file:///e:/a_VibeCoding/EcoPulse/scripts/prepare_serving_data.py)) 让前端 Streamlit 去读取？

---    *   **后果**：这完全违背了大数据架构的设计初衷。你把大数据的“大”强行压缩成了单机的“小”。如果 ADS 层结果膨胀到 1GB，你的看板内存会直接爆炸。

    *   **导师建议**：真正的 Serving 层应该是 **低延迟的 KV 存储（如 HBase, Redis）** 或者 **OLAP 引擎（如 ClickHouse, Doris）**。前端应该通过 API 接口查询数据库，而不是读本地文件。

## 一、 架构设计的 "头重脚轻" (Architecture Asymmetry)

2.  **调度系统的缺失**：

这是你项目目前最大的硬伤。    *   **批评**：我看你的运行方式还是“手动挡”——先运行这个脚本，再运行那个脚本。`启动看板.bat` 只是一个脚本聚合，不是调度。

    *   **后果**：在真实数仓中，ETL 任务之间有复杂的依赖关系（DWD 必须在 ODS 后，ADS 必须在 DWD 后）。没有 **Airflow** 或 **DolphinScheduler** 这种工作流编排工具，你的项目就是一个无法自动化运行的“半成品”。

### 1.1 Serving 层的伪分布式

### 二、 算法深度的“浅尝辄止” (Algorithmic Depth)

*   **批评**：你后端用了 Spark 这种重型核武器去处理 2 亿条数据，结果到了 Serving 层（服务层），你居然把结果导成了 **CSV 文件** (`scripts/prepare_serving_data.py`) 让前端 Streamlit 去读取？

*   **后果**：这完全违背了大数据架构的设计初衷。你把大数据的 "大" 强行压缩成了单机的 "小"。如果 ADS 层结果膨胀到 1GB，你的看板内存会直接爆炸。你用了 K-Means 和 RFM，这很好，但对于毕业设计来说，这太“标准”了，缺乏亮点。

*   **导师建议**：真正的 Serving 层应该是 **低延迟的 KV 存储（如 HBase, Redis）** 或者 **OLAP 引擎（如 ClickHouse, Doris）**。前端应该通过 API 接口查询数据库，而不是读本地文件。

1.  **仅有描述，没有预测**：

### 1.2 调度系统的缺失    *   **批评**：你的项目全是 **Descriptive Analytics（描述性分析）**——告诉别人“过去发生了什么”（谁买了、谁走了）。但高价值的大数据项目需要 **Predictive Analytics（预测性分析）**。

    *   **质问**：你既然已经算出了 RFM 和流失用户，为什么不更进一步？为什么没有 **Churn Prediction（流失预测模型）**？为什么没有基于协同过滤的 **Recommendation System（商品推荐）**？

*   **批评**：我看你的运行方式还是 "手动挡" —— 先运行这个脚本，再运行那个脚本。`启动看板.bat` 只是一个脚本聚合，不是调度。    *   **后果**：这导致你的项目看起来像一个高级 Excel 报表，而不是一个智能决策系统。

*   **后果**：在真实数仓中，ETL 任务之间有复杂的依赖关系（DWD 必须在 ODS 后，ADS 必须在 DWD 后）。没有 **Airflow** 或 **DolphinScheduler** 这种工作流编排工具，你的项目就是一个无法自动化运行的 "半成品"。

2.  **K-Means 的随意性**：

### 1.3 ⭐【新增】数仓分层混乱 — ODS 层缺失    *   **批评**：我看到了你用了 K-Means [ml_kmeans_clustering.py](file:///e:/a_VibeCoding/EcoPulse/CoreCode4/ml_kmeans_clustering.py)，轮廓系数 0.478。你为什么选 K=4？有做 Elbow Method（手肘法）分析图吗？特征工程除了 Log 化还做了什么？

    *   **导师建议**：算法的论证过程比结果更重要。在论文里，你必须证明“为什么选这个算法”以及“为什么这个参数是最优的”。

*   **批评**：你的 README 和 Mermaid 图中画了 `Raw → ODS → DWD → ADS`，但实际代码中 **根本不存在 ODS 层**。`etl_dwd_user_behavior.py` 直接从 `data/dwd/sample_oct_2019`（Phase 1 的采样产出）读取，而不是从原始 CSV。你的 `data/row/` 目录下有 7 个月度原始 CSV（2 亿+条），但没有任何脚本对它们做全量接入。

*   **质问**：那你 Phase 2 ETL 处理的 4200 万条数据到底是全部 7 个月的，还是只有 10 月的样本？如果只是 10 月，你 README 里写的 "2 亿+ 条" 就是虚假宣传。### 三、 数据治理的“真空地带” (Data Governance)

*   **后果**：这意味着你的数仓分层只停留在 PPT 上。在答辩时，老师一追问 "你的 ODS 层在哪里"，你就会露馅。

*   **整改**：要么写一个真正的全量接入脚本 `ods_ingest.py`，把 7 个月 CSV 统一转成 Parquet ODS 层；要么在论文里诚实说明 "受限于单机资源，仅使用 10 月数据做演示"。你处理了数据，但没有管理数据。



### 1.4 ⭐【新增】Spark Session 配置的 "复制粘贴病"1.  **缺乏增量机制**：

    *   **批评**：你的 ETL 脚本 [etl_dwd_user_behavior.py](file:///e:/a_VibeCoding/EcoPulse/CoreCode2/etl_dwd_user_behavior.py) 看起来是全量覆盖。如果明天新来了一天的日志，你是要把 2 亿条数据重新跑一遍吗？

*   **批评**：你每一个 `.py` 文件里都有一个几乎一模一样的 `get_spark_session()` 函数，硬编码了 `JAVA_HOME = r"E:\Java\jdk1.8.0_291"`、`spark.driver.memory = "6g"` 等配置。6 个 Phase 的 CoreCode 目录加起来，这段代码重复了至少 **8 次**。    *   **后果**：没有 **增量更新（Incremental Update）** 机制的大数据项目，在计算成本上是不可接受的。

*   **后果**：这是最典型的 **DRY 原则 (Don't Repeat Yourself)** 违反。如果你换一台机器，需要修改 8 个文件。这种代码在工程审计中会被标记为 "代码异味 (Code Smell)"。

*   **整改**：抽取为一个 `common/spark_config.py` 模块，所有脚本共享同一份配置。JAVA_HOME 通过环境变量注入，不要硬编码路径。2.  **数据质量监控 (DQC) 薄弱**：

    *   **批评**：虽然你有一个 `verify_ads.py`，但这远远不够。如果原始数据中某一天的数据量突然暴跌 50%（上游故障），你的系统能自动报警并阻断后续任务吗？

---    *   **导师建议**：需要引入数据质量卡点（Data Quality Check），比如空值率校验、主键唯一性校验、波动率校验。



## 二、 算法深度的 "浅尝辄止" (Algorithmic Depth)### 四、 创新性与应用价值 (Innovation & Value)



你用了 K-Means 和 RFM，这很好，但对于毕业设计来说，这太 "标准" 了，缺乏亮点。1.  **同质化严重**：

    *   **评价**：电商日志分析是大数据毕设中最常见的题目，大概 10 个学生里有 3 个做这个。

### 2.1 仅有描述，没有预测    *   **破局点**：你的 **可视化看板 (CoreCode6)** 是一个亮点，动画效果和交互做得很好，这稍微挽回了一些分数。但如果只靠“好看”是拿不到优秀的。

    *   **导师建议**：你需要强调 **性能优化**。你在 README 里提到了“加盐聚合 (Salting) 解决数据倾斜”，这非常好！这是真正的工程难点。在答辩时，要死磕这一点：**“如果不加盐，Spark 任务会跑死，加了盐提升了 16.3%”**，这才是体现你水平的地方。

*   **批评**：你的项目全是 **Descriptive Analytics（描述性分析）** —— 告诉别人 "过去发生了什么"（谁买了、谁走了）。但高价值的大数据项目需要 **Predictive Analytics（预测性分析）**。

*   **质问**：你既然已经算出了 RFM 和流失用户，为什么不更进一步？为什么没有 **Churn Prediction（流失预测模型）**？为什么没有基于协同过滤的 **Recommendation System（商品推荐）**？---

*   **后果**：这导致你的项目看起来像一个高级 Excel 报表，而不是一个智能决策系统。

### 🎓 导师最终评价与整改意见

### 2.2 K-Means 的随意性

**评分预估**：如果你现在去答辩，成绩大概在 **良 (B+)**。如果想冲 **优 (A)**，必须解决以下问题：

*   **批评**：我看到了你用了 K-Means (`ml_kmeans_clustering.py`)，轮廓系数 0.478。你为什么选 K=4？有做 Elbow Method（手肘法）分析图吗？特征工程除了 Log 化还做了什么？

*   **导师建议**：算法的论证过程比结果更重要。在论文里，你必须证明 "为什么选这个算法" 以及 "为什么这个参数是最优的"。**整改清单 (To-Do List)：**



### 2.3 ⭐【新增】RFM 分群逻辑前后矛盾1.  **架构升级（加分项）**：

    *   哪怕是伪造，也要模拟一个 **MySQL/Redis** 作为 Serving 层。写一个脚本把 CSV 灌入数据库，Streamlit 从数据库读。这代表你懂“分层存储”。

*   **批评**：我仔细对比了你两处 RFM 分群代码：2.  **算法增强（关键项）**：

    *   `analysis_rfm.py`（Spark 端）：只有 4 个分群 — "核心客户 / 流失预警 / 新客户 / 普通客户"，且逻辑非常粗糙（`> 3` 就是高，`≤ 3` 就是低）。    *   增加一个**预测模型**（如：使用 Logistic Regression 或 XGBoost 预测下个月可能流失的用户），并输出一份“高危流失名单”。这会让你的项目从“看数据”变成“用数据”。

    *   `prepare_serving_data.py`（Pandas 端）：重新算了 8 个分群 — "Champions / Potential Loyalist / …"，用了完全不同的阈值逻辑。3.  **工程化包装（防守项）**：

*   **质问**：你的 "真正分群" 到底发生在 Spark 端还是 Pandas 端？如果 ADS 层的 Parquet 里存的是 4 分群，然后 Serving 脚本又偷偷改成 8 分群，那你 ADS 层的数据完整性在哪里？`verify_ads.py` 校验的是 4 分群还是 8 分群？    *   在论文/文档中，着重描写 **Spark 数据倾斜治理** 和 **Parquet 存储优化** 的过程。这是你区别于只会写 SQL 的学生的核心竞争力。

*   **后果**：这种 "后门修补" 方式在数据治理中是大忌 —— 下游消费者看到的数据和中间层存储的数据不一致，叫做 **数据漂移 (Data Drift)**。4.  **实时性思考（展望项）**：

*   **整改**：8 分群逻辑必须提前到 `analysis_rfm.py` 的 Spark 端完成，写入 ADS Parquet。`prepare_serving_data.py` 应该只做格式转换，不做业务逻辑变更。    *   在“不足与展望”章节，必须深刻检讨“离线批处理”的滞后性，并提出“Lambda 架构”或“Flink 实时数仓”的改进方案。



### 2.4 ⭐【新增】Elbow Method 有名无实**一句话总结**：

你的前端工程化能力很强（CoreCode6 很漂亮），但后端数据工程还不够“硬核”。**不要让漂亮的 UI 掩盖了数据架构的简陋**。

*   **批评**：你代码注释写了 "肘部法 (寻找最佳 K 值)"，循环了 K=2~6 并打印了 Silhouette Score，但最后直接硬编码 `best_k = 4`。你没有做 WSSSE (Within-Set Sum of Squared Errors) 的 Elbow 拐点检测，也没有输出任何图表。这不叫 Elbow Method，这叫 "手动指定了一个数字"。

*   **整改**：
    1.  同时记录 WSSSE 和 Silhouette Score，绘制双 Y 轴折线图。
    2.  用代码自动识别拐点（如 KneeLocator），而不是人工选择。
    3.  将选择过程和最终图表输出到 `outputs/ml/` 目录，作为论文附录素材。

---

## 三、 数据治理的 "真空地带" (Data Governance)

你处理了数据，但没有管理数据。

### 3.1 缺乏增量机制

*   **批评**：你的 ETL 脚本 (`etl_dwd_user_behavior.py`) 看起来是全量覆盖 (`write.mode("overwrite")`)。如果明天新来了一天的日志，你是要把 2 亿条数据重新跑一遍吗？
*   **后果**：没有 **增量更新（Incremental Update）** 机制的大数据项目，在计算成本上是不可接受的。

### 3.2 数据质量监控 (DQC) 薄弱

*   **批评**：虽然你有一个 `verify_ads.py`，但这远远不够。如果原始数据中某一天的数据量突然暴跌 50%（上游故障），你的系统能自动报警并阻断后续任务吗？
*   **导师建议**：需要引入数据质量卡点（Data Quality Check），比如空值率校验、主键唯一性校验、波动率校验。

### 3.3 ⭐【新增】ETL 清洗深度不足

*   **批评**：你的 `etl_dwd_user_behavior.py` 清洗逻辑只做了两件事：① `dropDuplicates()`（全字段去重），② 标记 `price <= 0` 为异常。这对于一个号称 "深度分析" 的项目来说，远远不够。
*   **缺失项**：
    *   **Bot / 爬虫过滤**：电商点击流数据中通常 10-30% 是机器流量（同一 user_id 在 1 秒内产生上百次 view）。你没有做任何 Session 频率异常检测。
    *   **Session 切割**：你的 `user_session` 字段直接来源于原始数据。如果上游 Session 定义不合理（比如超过 30 分钟无活动还算同一 Session），你的漏斗分析会严重失真。你有校验过吗？
    *   **价格异常只标记不处理**：你标记了 `price_is_illegal = 1`，但下游的 RFM 计算 (`analysis_rfm.py`) 并没有过滤掉这些记录。这意味着 `monetary = 0` 的用户也被纳入了 RFM 评分，直接污染了分群结果。
*   **整改**：
    1.  增加 Session 频率异常检测，过滤疑似 Bot 流量。
    2.  RFM 计算时必须 `filter(col("price_is_illegal") == 0)`。
    3.  在论文中用一节专门讲 "数据清洗策略与异常处理"。

### 3.4 ⭐【新增】缺乏数据血缘与元数据管理

*   **批评**：你的项目中没有任何 **数据字典** 是自动化维护的。`data_dictionary.md` 是手写的静态文档，如果字段改了，文档不会自动更新。也没有任何数据血缘 (Data Lineage) 追踪 —— 我无法从任何一张 ADS 表反向追溯它的加工逻辑来自哪个 DWD 字段。
*   **整改**：哪怕做不到 Atlas/DataHub 级别，至少在每个 ADS 输出的 Parquet 目录下放一个 `_metadata.json`，记录数据来源、处理脚本、行数、生成时间戳。

---

## 四、 创新性与应用价值 (Innovation & Value)

### 4.1 同质化严重

*   **评价**：电商日志分析是大数据毕设中最常见的题目，大概 10 个学生里有 3 个做这个。
*   **破局点**：你的 **可视化看板 (CoreCode6)** 是一个亮点，动画效果和交互做得很好，这稍微挽回了一些分数。但如果只靠 "好看" 是拿不到优秀的。
*   **导师建议**：你需要强调 **性能优化**。你在 README 里提到了 "加盐聚合 (Salting) 解决数据倾斜"，这非常好！这是真正的工程难点。在答辩时，要死磕这一点：**"如果不加盐，Spark 任务会跑死，加了盐提升了 16.3%"**，这才是体现你水平的地方。

### 4.2 ⭐【新增】加盐实验的科学性存疑

*   **批评**：我看了你 `perf_skew_optimization.py` 的代码。你对比的是 "普通 `groupBy('brand')` 聚合" vs "加盐聚合"，然后声称提升了 16.3%。但有几个严重问题：
    1.  **没有预热**：Spark 的第一次查询通常包含 JIT 编译和数据序列化开销。你先跑了普通聚合，再跑加盐聚合，第二次天然更快，这叫 **缓存效应 (Caching Bias)**。你应该先跑一次 `df.count()` 做 warmup。
    2.  **单次运行**：你只跑了一次就取结论。在性能基准测试中，至少要 **重复 3-5 次取中位数**，排除抖动。
    3.  **数据规模太小**：你在 4200 万条数据上做 `brand` 聚合，brand 的 cardinality（基数）可能有上千个。加盐对高基数 Key 的效果本来就不明显，只有当某几个 Key 占据 80%+ 数据时才有意义。你有分析过 brand 的分布倾斜度吗？
*   **后果**：如果答辩老师追问 "16.3% 的显著性怎么保证？"，你无法回答。
*   **整改**：增加 warmup 轮次、多次运行取中位数、绘制箱线图，并对比不同 salt_range 的效果。

---

## 五、 ⭐【新增】工程规范的 "学生气" (Engineering Maturity)

这一部分是原版本没有提及、但在答辩中老师必问的软实力。

### 5.1 零测试覆盖

*   **批评**：整个项目 **没有一个 pytest 测试文件**。没有单元测试、没有集成测试、没有回归测试。你的 `benchmark_corecode6.py` 只是一个手动检查脚本，不是测试框架。
*   **后果**：如果你改了 `analysis_rfm.py` 的分群逻辑，你怎么保证下游的 `prepare_serving_data.py` 还能正常工作？答案是 —— 你不知道，只能手动跑一遍看看。这在任何正经的软件项目中都是不可接受的。
*   **整改**：至少为核心模块编写 pytest 测试：
    *   `test_rfm.py`：输入固定的 R/F/M 分数，断言分群结果正确。
    *   `test_funnel.py`：输入已知行为序列，断言漏斗计算正确。
    *   `test_prepare_serving.py`：断言 CSV 输出字段完整、行数非零。

### 5.2 依赖管理形同虚设

*   **批评**：你的根目录 `requirements.txt` 里只有一行 `tzdata==2025.3`。而 `CoreCode6/requirements.txt` 里有 `pandas>=2.0`、`streamlit>=1.41` 等。这两个文件互相矛盾 —— 你的项目到底依赖什么？
*   **后果**：如果我 `git clone` 你的项目然后 `pip install -r requirements.txt`，我只会装一个 `tzdata`，什么都跑不起来。
*   **整改**：根目录 `requirements.txt` 必须包含项目 **所有** 依赖（包括 pyspark、pandas、streamlit、plotly、pyarrow）。建议用 `pip freeze > requirements.txt` 重新生成，或者用 `pyproject.toml` 管理。

### 5.3 日志系统的原始

*   **批评**：你每个脚本都用 `logging.basicConfig()` 独立配置日志，重复配置了 8 次以上。日志文件只按日期命名（如 `etl_dwd_20260211.log`），没有日志轮转 (Rotation)、没有结构化日志 (JSON Logging)、没有统一的日志级别控制。
*   **整改**：统一为一个 `common/logger.py` 配置模块，支持 `RotatingFileHandler`，考虑使用 `structlog` 或 `python-json-logger` 输出结构化日志。

### 5.4 缺乏 CI/CD 与代码质量门禁

*   **批评**：你的 GitHub 仓库没有 `.github/workflows/` 目录 —— 没有 GitHub Actions、没有自动化检查。任何人（包括你自己）可以直接推送破坏性代码到 main 分支。
*   **整改**：至少配置一个简单的 CI Pipeline：`flake8` 代码检查 + `pytest` 自动运行。

### 5.5 安全性与配置外泄

*   **批评**：`JAVA_HOME` 被硬编码为 `r"E:\Java\jdk1.8.0_291"` —— 这是你个人电脑的路径，出现在了要推送到 GitHub 的代码中。如果这是数据库密码呢？
*   **整改**：所有环境相关路径通过 `.env` 文件或 `os.environ` 读取，`.env` 加入 `.gitignore`。提供 `.env.example` 作为模板。

---

## 六、 ⭐【新增】可视化看板的隐患 (CoreCode6 Deep Dive)

CoreCode6 是你的亮点，但越亮的地方，瑕疵越刺眼。

### 6.1 数据加载无容错

*   **批评**：`utils.py` 的 `load_data()` 函数（虽然加了 `st.cache_data`），如果任意一个 CSV 文件缺失或格式错误，Streamlit 会直接白屏崩溃。你在 `app.py` 里只对 `df_funnel.empty` 做了检查，但没有对其他三个 DataFrame 做 null 检查。
*   **整改**：`load_data()` 应该对每个 CSV 做 try-except 包裹，返回空 DataFrame 并在 UI 上显示具体的错误提示。

### 6.2 看板只有 1 个月数据

*   **批评**：如果你的 DWD 层实际只处理了 10 月数据（见 1.3 节），那你的看板日期选择器只能选 2019-10-01 到 2019-10-31。一个月的数据做 "留存分析" 和 "趋势分析"，结论的统计意义非常有限。
*   **后果**：答辩老师会问："你声称做了 7 个月的分析，为什么看板只有 1 个月的数据？"

### 6.3 缺少异常状态 UI

*   **批评**：当数据为空、加载失败或筛选范围无结果时，看板只显示一个红色 `st.error()` 就停了。没有 Empty State（空状态设计）、没有 Loading Skeleton（加载骨架屏）、没有 Retry 按钮。
*   **整改**：为每个图表区域添加 graceful degradation（优雅降级）设计。

---

## 🎓 导师最终评价与整改意见

### 评分预估

| 维度 | 当前评分 | 冲优目标 |
| :--- | :--- | :--- |
| 数据架构 | C+ (分层只在纸面) | B+ (补 ODS + 增量) |
| 算法深度 | B- (有 RFM + K-Means) | A- (加预测模型) |
| 工程规范 | C (无测试/依赖混乱) | B+ (加 pytest + CI) |
| 可视化 | A- (动画引擎很好) | A (修复容错 + 多月数据) |
| 论文表达 | 待定 | 着重写 Spark 调优过程 |
| **综合** | **B (良)** | **A- ~ A (优)** |

### 整改清单 (按优先级排序)

**P0 — 必须修复（不修直接扣分）**：

1.  **修复 `requirements.txt`**：根目录必须包含全部依赖。
2.  **RFM 分群逻辑统一**：8 分群必须在 Spark 端完成，Serving 脚本只做格式转换。
3.  **抽取公共模块**：`get_spark_session()` 和日志配置抽取到 `common/` 目录。
4.  **去掉硬编码路径**：JAVA_HOME 改为环境变量读取。

**P1 — 强烈建议（冲优必做）**：

5.  **架构升级**：哪怕是伪造，也要模拟一个 **MySQL/Redis** 作为 Serving 层。写一个脚本把 CSV 灌入数据库，Streamlit 从数据库读。这代表你懂 "分层存储"。
6.  **算法增强**：增加一个 **预测模型**（如：使用 Logistic Regression 或 XGBoost 预测下个月可能流失的用户），并输出一份 "高危流失名单"。这会让你的项目从 "看数据" 变成 "用数据"。
7.  **补充 pytest 测试**：至少 3 个测试文件，覆盖 RFM / 漏斗 / 数据加载。
8.  **修复加盐实验**：增加 warmup + 多次运行 + 箱线图。

**P2 — 加分项（有能力就做）**：

9.  **增量 ETL 机制**：DWD 层支持 `append` 模式，按日期分区增量写入。
10. **简易 CI Pipeline**：`.github/workflows/ci.yml` 跑 `flake8` + `pytest`。
11. **数据质量卡点**：ETL 前后自动校验行数波动、空值率、主键唯一性。
12. **Elbow Method 可视化**：输出 K vs Silhouette / WSSSE 双轴折线图到 `outputs/ml/`。

**P3 — 展望项（写进论文 "不足与展望"）**：

13. **实时性思考**：深刻检讨 "离线批处理" 的滞后性，并提出 "Lambda 架构" 或 "Flink 实时数仓" 的改进方案。
14. **安全与权限**：讨论数据脱敏、行级权限控制 (Row-Level Security) 等生产级需求。
15. **容器化部署**：Dockerfile + docker-compose 一键启动全栈环境。

---

### 一句话总结

你的前端工程化能力很强（CoreCode6 很漂亮），但后端数据工程还不够 "硬核"。**不要让漂亮的 UI 掩盖了数据架构的简陋**。当务之急不是继续加动画，而是回头把地基打扎实 —— **修依赖、统一逻辑、补测试、写清楚论文中的技术决策过程**。
